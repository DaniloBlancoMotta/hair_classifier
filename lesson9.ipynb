{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração Inicial e Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar reprodutibilidade\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download do dataset\n",
    "data_url = \"https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\"\n",
    "data_file = \"data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_file):\n",
    "    print(f\"Downloading {data_file}...\")\n",
    "    response = requests.get(data_url, stream=True)\n",
    "    with open(data_file, \"wb\") as f:\n",
    "        for chunk in tqdm(response.iter_content(chunk_size=1024)):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(f\"{data_file} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir = \"data\"\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(f\"Extracting {data_file}...\")\n",
    "    with zipfile.ZipFile(data_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\".\")\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(f\"{extract_dir} directory already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(extract_dir, 'train')\n",
    "test_dir = os.path.join(extract_dir, 'test')\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    classes = os.listdir(train_dir)\n",
    "    print(f\"Classes encontradas no conjunto de treino: {classes}\")\n",
    "    print(f\"Número de classes: {len(classes)}\")\n",
    "    \n",
    "    if len(classes) == 2:\n",
    "        print(\"\\nConclusão: Como existem 2 classes, este é um problema de Classificação Binária.\")\n",
    "        print(\"Recomendação: Usar nn.BCEWithLogitsLoss()\")\n",
    "    else:\n",
    "        print(f\"\\nConclusão: Como existem {len(classes)} classes, este é um problema de Classificação Multiclasse.\")\n",
    "        print(\"Recomendação: Usar nn.CrossEntropyLoss()\")\n",
    "else:\n",
    "    print(f\"Diretório {train_dir} não encontrado. Verifique a extração.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.Resampling.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download e Inspeção do Modelo ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/\"\n",
    "files = [\"hair_classifier_v1.onnx\", \"hair_classifier_v1.onnx.data\"]\n",
    "\n",
    "for file_name in files:\n",
    "    if not os.path.exists(file_name):\n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        response = requests.get(base_url + file_name)\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"{file_name} downloaded.\")\n",
    "    else:\n",
    "        print(f\"{file_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "session = ort.InferenceSession(\"hair_classifier_v1.onnx\")\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "print(f\"Input name: {input_name}\")\n",
    "print(f\"Output name: {output_name}\")\n",
    "\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "print(f\"Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação da Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "\n",
    "target_height = input_shape[2]\n",
    "target_width = input_shape[3]\n",
    "target_size = (target_width, target_height)\n",
    "\n",
    "print(f\"Input shape do modelo: {input_shape}\")\n",
    "print(f\"Target size para redimensionamento: {target_size}\")\n",
    "\n",
    "img = download_image(image_url)\n",
    "img_prepared = prepare_image(img, target_size)\n",
    "\n",
    "plt.imshow(img_prepared)\n",
    "plt.title(f\"Imagem redimensionada para {target_size}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 255.0\n",
    "    return x\n",
    "\n",
    "x = np.array(img_prepared, dtype='float32')\n",
    "X = np.array([x])\n",
    "X = preprocess_input(X)\n",
    "\n",
    "X = X.transpose(0, 3, 1, 2)\n",
    "\n",
    "print(f\"Shape final: {X.shape}\")\n",
    "\n",
    "r_value = X[0, 0, 0, 0]\n",
    "print(f\"Valor do primeiro pixel (R channel): {r_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação do Pré-processamento\n",
    "\n",
    "Cálculo para o canal R:\n",
    "$$ \\text{Normalized} = \\frac{\\text{Value}/255.0 - \\text{Mean}}{\\text{Std}} $$\n",
    "$$ \\text{Normalized} = \\frac{0.2392 - 0.485}{0.229} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_imagenet(x):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    x /= 255.0\n",
    "    x -= mean\n",
    "    x /= std\n",
    "    return x\n",
    "\n",
    "img = download_image(image_url)\n",
    "img_prepared = prepare_image(img, target_size)\n",
    "\n",
    "x = np.array(img_prepared, dtype='float32')\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input_imagenet(X)\n",
    "\n",
    "X = X.transpose(0, 3, 1, 2)\n",
    "\n",
    "r_value_norm = X[0, 0, 0, 0]\n",
    "print(f\"Valor do primeiro pixel (R channel) com normalização ImageNet: {r_value_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executar Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = session.run([output_name], {input_name: X})\n",
    "output_value = outputs[0][0]\n",
    "\n",
    "print(f\"Raw output do modelo: {output_value}\")\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "probability = sigmoid(output_value)\n",
    "print(f\"Probabilidade (após Sigmoid): {probability}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}